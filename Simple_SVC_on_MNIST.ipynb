{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_a = np.array([[100,200,300,400,500,600],[1,2,2,2,4,9]])\n"
      ],
      "metadata": {
        "id": "Tm2_lO3NwDzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.pad(test_a,(14,(0,0)),mode='median'))"
      ],
      "metadata": {
        "id": "ZB5HfcjCwVae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T9wWW0D71Vb"
      },
      "outputs": [],
      "source": [
        ",import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def cross_validation_error(X, y, model, folds):\n",
        "    samples_sub_arrays = np.array_split(X, folds)\n",
        "    labels_sub_arrays = np.array_split(y, folds)\n",
        "    error_k_train = []\n",
        "    error_k_test = []\n",
        "    for k in range(folds):\n",
        "        # Split the array into sub-arrays of approximately the same size.\n",
        "        # Choose the k-th array as the test array, and combine all others as the training set.\n",
        "        X_test = samples_sub_arrays.pop(k)\n",
        "        y_test = labels_sub_arrays.pop(k)\n",
        "        X_train = np.vstack(samples_sub_arrays)\n",
        "        y_train = np.concatenate(labels_sub_arrays)\n",
        "        model.fit(X_train, y_train)\n",
        "        # Calculate error on training set\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        error_count = 0\n",
        "        for i in range(len(y_train)):\n",
        "            if y_pred_train[i] != y_train[i]:\n",
        "                error_count += 1\n",
        "        error_k_train.append(error_count / len(y_train))\n",
        "        # Calculate error on test set\n",
        "        y_pred_test = model.predict(X_test)\n",
        "        error_count = 0\n",
        "        for i in range(len(y_pred_test)):\n",
        "            if y_pred_test[i] != y_test[i]:\n",
        "                error_count += 1\n",
        "        error_k_test.append(error_count / len(y_test))\n",
        "        # Return the chosen sub-arrays back with all training points\n",
        "        samples_sub_arrays.insert(k, X_test)\n",
        "        labels_sub_arrays.insert(k, y_test)\n",
        "    avg_error = (sum(error_k_train)/folds, sum(error_k_test)/folds)\n",
        "    return avg_error\n",
        "\n",
        "\n",
        "def svm_results(X_train, y_train, X_test, y_test):\n",
        "    error_results = {}\n",
        "    error = 0\n",
        "    model = SVC(kernel='linear')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    for i in range(len(y_test)):\n",
        "        if y_test[i] != y_pred[i]:\n",
        "            error = error + 1\n",
        "    test_error = error/len(y_test)\n",
        "    CV_error = cross_validation_error(X_train, y_train, model, 4)\n",
        "    error_results['SVM_linear'] = (CV_error[0], CV_error[1], test_error)\n",
        "    for d in range(2, 10, 2):\n",
        "        model = SVC(kernel='poly', degree=d)\n",
        "        error = 0\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        for i in range(len(y_test)):\n",
        "            if y_test[i] != y_pred[i]:\n",
        "                error = error + 1\n",
        "        test_error = error/len(y_test)\n",
        "        error_results[f'SVM_poly_{d}'] = (CV_error[0], CV_error[1], test_error)\n",
        "    rbf_values = [0.001, 0.01, 0.1, 1.0, 10]\n",
        "    for val in rbf_values:\n",
        "        model = SVC(kernel='rbf', gamma=val)\n",
        "        error = 0\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        for i in range(len(y_test)):\n",
        "            if y_test[i] != y_pred[i]:\n",
        "                error = error + 1\n",
        "        test_error = error / len(y_test)\n",
        "        error_results[f'SVM_poly_{val}'] = (CV_error[0], CV_error[1], test_error)\n",
        "    return error_results\n",
        "\n",
        "\n",
        "def fetch_mnist():\n",
        "    # Download MNIST dataset\n",
        "    X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True)\n",
        "    X = X.to_numpy()\n",
        "    y = y.to_numpy()\n",
        "\n",
        "    # Randomly sample 7000 images\n",
        "    np.random.seed(2)\n",
        "    indices = np.random.choice(len(X), 7000, replace=False)\n",
        "    X, y = X[indices], y[indices]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def main():\n",
        "    X, y = fetch_mnist()\n",
        "    print(X.shape, y.shape)\n",
        "    idx2class = {'0': 'T-shirt/top', '1': 'Trouser', '2': 'Pullover', '3': 'Dress', '4': 'Coat', '5': 'Sandal',\n",
        "                 '6': 'Shirt', '7': 'Sneaker', '8': 'Bag', '9': 'Ankle'}\n",
        "    for i in range(10):\n",
        "        image = X[i].reshape(28, 28)\n",
        "        s = idx2class[y[i]]\n",
        "        plt.title(f'{y[i]}, {s}')\n",
        "        plt.imshow(image, cmap='binary')\n",
        "        plt.show()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "    error_res = svm_results(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    train_cv_error = []\n",
        "    test_cv_error = []\n",
        "    test_error = []\n",
        "    labels_names = []\n",
        "    index_range = range(len(error_res.keys()))\n",
        "    for key in error_res.keys():\n",
        "        train_cv_error.append(error_res[key][0])\n",
        "        test_cv_error.append(error_res[key][1])\n",
        "        test_error.append(error_res[key][2])\n",
        "        labels_names.append(key)\n",
        "\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.set_xlabel(\"Model\")\n",
        "    ax1.set_ylabel(\"Error Rate\")\n",
        "    width = 0.2\n",
        "    ax1.bar([val - width for val in index_range], train_cv_error, width=width, color='blue', label='Train CV Error')\n",
        "    ax1.bar([val for val in index_range], test_cv_error, width=width, color='red', label='Test CV Error')\n",
        "    ax1.bar([val + width for val in index_range], test_error, width=width, color='green', label='Test Error')\n",
        "    ax1.set_xticks(index_range, labels_names, rotation=90)\n",
        "    plt.title(\"Comparison between different models\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}